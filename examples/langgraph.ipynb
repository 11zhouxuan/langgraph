{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "396e20d9-8684-40ea-a46a-e3dfa36ed5a6",
      "metadata": {},
      "source": [
        "## Existing Agent Executor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "d642e6af-217a-4414-a78c-509b44155eca",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain import hub\n",
        "from langchain.agents import create_openai_functions_agent\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain_community.chat_models import ChatOpenAI\n",
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "\n",
        "from langgraph.graph import END, Graph\n",
        "\n",
        "tools = [TavilySearchResults(max_results=1)]\n",
        "\n",
        "# Get the prompt to use - you can modify this!\n",
        "prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
        "\n",
        "# Choose the LLM that will drive the agent\n",
        "llm = ChatOpenAI(model=\"gpt-3.5-turbo-1106\")\n",
        "\n",
        "# Construct the OpenAI Functions agent\n",
        "agent_runnable = create_openai_functions_agent(llm, tools, prompt)\n",
        "\n",
        "from langchain_core.agents import AgentFinish\n",
        "# Define decision-making logic\n",
        "def should_continue(data):\n",
        "    # Logic to decide whether to continue in the loop or exit\n",
        "    if isinstance(data['agent_outcome'], AgentFinish):\n",
        "        return \"exit\"\n",
        "    else:\n",
        "        return \"continue\"\n",
        "    \n",
        "def execute_tools(data):\n",
        "    agent_action = data.pop('agent_outcome')\n",
        "    observation = {t.name: t for t in tools}[agent_action.tool].invoke(agent_action.tool_input)\n",
        "    data['intermediate_steps'].append((agent_action, observation))\n",
        "    return data\n",
        "    \n",
        "    \n",
        "\n",
        "# Define agents\n",
        "agent = RunnablePassthrough.assign(\n",
        "    agent_outcome = agent_runnable\n",
        ")\n",
        "\n",
        "\n",
        "# Define a new graph\n",
        "workflow = Graph()\n",
        "\n",
        "workflow.add_node(\"agent\", agent)\n",
        "workflow.add_node(\"tools\", execute_tools)\n",
        "\n",
        "workflow.set_entry_point(\"agent\")\n",
        "\n",
        "workflow.add_conditional_edges(\n",
        "    \"agent\",\n",
        "    should_continue,\n",
        "    {\n",
        "        \"continue\": \"tools\",\n",
        "        \"exit\": END\n",
        "    }\n",
        ")\n",
        "\n",
        "workflow.add_edge('tools', 'agent')\n",
        "\n",
        "chain = workflow.compile()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "c46bd262-9605-4449-9391-f6b6e0fe440e",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'input': 'what is the weather in sf',\n",
              " 'intermediate_steps': [(AgentActionMessageLog(tool='tavily_search_results_json', tool_input={'query': 'weather in San Francisco'}, log=\"\\nInvoking: `tavily_search_results_json` with `{'query': 'weather in San Francisco'}`\\n\\n\\n\", message_log=[AIMessage(content='', additional_kwargs={'function_call': {'name': 'tavily_search_results_json', 'arguments': '{\"query\":\"weather in San Francisco\"}'}})]),\n",
              "   [{'url': 'https://www.weather25.com/north-america/usa/california/san-francisco',\n",
              "     'content': 'will give you an idea of weather trends in San Francisco. For example, the weather in San Francisco in January 2024.  San Francisco 14 day weather The weather today in San Francisco San Francisco weather report  The weather in San Francisco, United States San Francisco weather by months San Francisco weather  the weather in San Francisco including humidity, wind, chance of rain and more on the San Francisco current weather01 January 02 February 03 March 04 April 05 May 06 June 07 July 08 August 09 September 10 October 11 November 12 December. ... For example, the weather in San Francisco in January 2024. These trends can be helpful when planning trips to San Francisco or preparing for the weather in advance. There are many factors to consider when looking at the ...'}])],\n",
              " 'agent_outcome': AgentFinish(return_values={'output': 'For the current weather in San Francisco, you can visit the following website: [San Francisco Weather](https://www.weather25.com/north-america/usa/california/san-francisco). This will provide you with the latest weather updates including humidity, wind, chance of rain, and more.'}, log='For the current weather in San Francisco, you can visit the following website: [San Francisco Weather](https://www.weather25.com/north-america/usa/california/san-francisco). This will provide you with the latest weather updates including humidity, wind, chance of rain, and more.')}"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chain.invoke({\"input\": \"what is the weather in sf\", \"intermediate_steps\": []})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "592c3886-71d1-4539-80dd-111e55cc3a85",
      "metadata": {},
      "source": [
        "## Reflexion Agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "f6f96e81-4a20-4599-a625-8d18df6fa76d",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain.agents import AgentExecutor, BaseMultiActionAgent, Tool\n",
        "from langchain.schema import AgentAction, AgentFinish\n",
        "from langchain_core.language_models.chat_models import BaseChatModel\n",
        "from langchain.chains import LLMChain\n",
        "\n",
        "from langchain.globals import set_llm_cache\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "from pydantic import BaseModel\n",
        "\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.cache import SQLiteCache\n",
        "\n",
        "from langchain_core.output_parsers import BaseOutputParser\n",
        "\n",
        "from langchain.prompts.chat import ChatPromptTemplate\n",
        "from langchain.callbacks import get_openai_callback\n",
        "from langchain.tools.tavily_search import TavilySearchResults\n",
        "from langchain.utilities.tavily_search import TavilySearchAPIWrapper\n",
        "from langchain.pydantic_v1 import BaseModel\n",
        "import os\n",
        "\n",
        "from langchain.agents import AgentType, initialize_agent, load_tools\n",
        "\n",
        "set_llm_cache(SQLiteCache(database_path=\".langchain.db\"))\n",
        "\n",
        "\n",
        "llm = ChatOpenAI(\n",
        "    temperature=0.0,\n",
        "    max_tokens=2000,\n",
        "    max_retries=100,\n",
        "    model=\"gpt-4-1106-preview\",\n",
        ")\n",
        "\n",
        "search = TavilySearchAPIWrapper()\n",
        "tavily_tool = TavilySearchResults(api_wrapper=search, max_results=5)\n",
        "\n",
        "NEXT_STEP_TEMPLATE = \"\"\"You are expert researcher trying answer a question ~250 words. You are asked to answer the following question: {question}\n",
        "\n",
        "The way you are going to answer the question is as follows:\n",
        "\n",
        "1. Revise your previous answer using the new information.\n",
        "    - You should use the previous critique to add important information to your answer.\n",
        "        _ You MUST include numerical citations in your revised answer to ensure it can be verified.\n",
        "        - Add a \"References\" section to the bottom of your answer (which does not count towards the word limit). In form of:\n",
        "            - [1] https://example.com\n",
        "            - [2] https://example.com\n",
        "    - You should use the previous critique to remove superfluous information from your answer and make SURE it is not more than 250 words.\n",
        "2. Reflect and critique your answer. Specifically, you should:\n",
        "    - Think about what is missing from your answer.\n",
        "    - Think about what is superfluous in your answer.\n",
        "    - Think about what search query you should use next to improve your answer.\n",
        "  Give your answer in exactly 2 parts. The first should address what is missing from your answer. The second should address what could be removed from your answer. Your should be VERY harsh as we really want to improve the answer.\n",
        "3. Give the search query you came up with to improve your answer.\n",
        "\n",
        "Previous steps: \n",
        "\n",
        "{previous_steps}\n",
        "\n",
        "===\n",
        "\n",
        "Format your answer as follows:\n",
        "\n",
        "Revised answer: [give your revised answer based on the previous critique and new information from the search engine then the \"References\" section]\n",
        "Critique: [give your harsh critique of your revised answer in 2 parts: what is missing and what is superfluous]\n",
        "Search query: [give the new search query you came up with to enter into the search engine to improve your answer. If you have more than one, make sure they are comma separated and in quotes]\n",
        "\n",
        "SAY NOTHING else please.\"\"\"\n",
        "\n",
        "INITIAL_ANSWER_TEMPLATE = \"\"\"You are expert researcher trying answer a question ~250 words. You are asked to answer the following question: {question}\n",
        "\n",
        "The way you are going to answer the question is as follows:\n",
        "\n",
        "1. Give a detailed in ~250 words.\n",
        "2. Reflect and critique your answer. Specifically, you should:\n",
        "    - Think about what is missing from your answer.\n",
        "    - Think about what is superfluous in your answer.\n",
        "    - Think about what search query you should use next to improve your answer.\n",
        "  Give your answer in exactly 2 parts. The first should address what is missing from your answer. The second should address what could be removed from your answer. Your should be VERY harsh as we really want to improve the answer.\n",
        "3. Give the search query you came up with to improve your answer.\n",
        "\n",
        "===\n",
        "\n",
        "Format your answer as follows:\n",
        "\n",
        "Answer: [give your initial answer]\n",
        "Critique: [give your harsh critique of your answer in 2 parts: what is missing and what is superfluous]\n",
        "Search query: [give the search query you came up with to improve your answer. If you have more than one, make sure they are comma separated and in quotes]\n",
        "\n",
        "SAY NOTHING else please.\"\"\"\n",
        "\n",
        "\n",
        "class ReflexionStep(BaseModel):\n",
        "    \"\"\"A single step in the reflexion process.\"\"\"\n",
        "\n",
        "    answer: str\n",
        "    critique: str\n",
        "    search_query: str\n",
        "\n",
        "    def __str__(self):\n",
        "        return f\"Answer: {self.answer}\\nCritique: {self.critique}\\nSearch query: {self.search_query}\"\n",
        "\n",
        "def _parse_reflexion_step(output: str) -> tuple[str, str, str]:\n",
        "    # find answer using .split()\n",
        "    if (\"Answer:\" not in output and \"Revised answer:\" not in output) or not \"Critique:\" in output or not \"Search query:\" in output:\n",
        "        raise ValueError(f\"The output is not formatted correctly. Output: {output}\")\n",
        "    if \"Answer:\" in output:\n",
        "        answer = output.split(\"Answer:\")[1].split(\"Critique:\")[0].strip()\n",
        "    else:\n",
        "        answer = output.split(\"Revised answer:\")[1].split(\"Critique:\")[0].strip()\n",
        "    critique = output.split(\"Critique:\")[1].split(\"Search query:\")[0].strip()\n",
        "    search_query = output.split(\"Search query:\")[1].strip()\n",
        "    return answer, critique, search_query\n",
        "\n",
        "class ReflexionStepParser(BaseOutputParser[ReflexionStep]):\n",
        "    \"\"\"Parser for the reflexion step.\"\"\"\n",
        "\n",
        "    def parse(self, output: str) -> ReflexionStep:\n",
        "        \"\"\"Parse the output.\"\"\"\n",
        "        # try to find answer or initial answer\n",
        "        answer, critique, search_query = _parse_reflexion_step(output)\n",
        "        return ReflexionStep(\n",
        "            answer=answer, critique=critique, search_query=search_query\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "7708fa95-547b-4bea-b126-3656de7d5873",
      "metadata": {},
      "outputs": [],
      "source": [
        "initial_chain = RunnablePassthrough.assign(\n",
        "    agent_outcome = ChatPromptTemplate.from_template(INITIAL_ANSWER_TEMPLATE) | llm | ReflexionStepParser() | (lambda x: AgentAction(\n",
        "                    tool=\"tavily_search_results_json\",\n",
        "                    tool_input=x.search_query,\n",
        "                    log=str(x),\n",
        "                ))\n",
        ")\n",
        "\n",
        "def prep_next(inputs):\n",
        "    intermediate_steps = inputs[\"intermediate_steps\"]\n",
        "    previous_steps = list[str]()\n",
        "\n",
        "    for i, (action, observation) in enumerate(intermediate_steps, start=1):\n",
        "        last_step_str = f\"\"\"Step {i}:\n",
        "\n",
        "{action.log}\n",
        "\n",
        "Search output for \"{action.tool_input}\":\n",
        "\n",
        "{observation}\"\"\"\n",
        "        previous_steps.append(last_step_str)\n",
        "\n",
        "    previous_steps_str = \"\\n\\n\".join(previous_steps)\n",
        "    inputs[\"previous_steps\"] = previous_steps_str\n",
        "    return inputs\n",
        "    \n",
        "next_chain = RunnablePassthrough.assign(\n",
        "    agent_outcome = prep_next | ChatPromptTemplate.from_template(NEXT_STEP_TEMPLATE) | llm | ReflexionStepParser() | (lambda x: AgentAction(\n",
        "                tool=\"tavily_search_results_json\",\n",
        "                tool_input=x.search_query,\n",
        "                log=str(x),\n",
        "            ))\n",
        ")\n",
        "\n",
        "def finish(inputs):\n",
        "    intermediate_steps = inputs[\"intermediate_steps\"]\n",
        "    last_action, _ = intermediate_steps[-1]\n",
        "    last_step_str = last_action.log\n",
        "    # extract answer\n",
        "    answer, _, _ = _parse_reflexion_step(last_step_str)\n",
        "\n",
        "    first_action, _ = intermediate_steps[0]\n",
        "    first_step_str = first_action.log\n",
        "    # extract answer\n",
        "    initial_answer, _, _ = _parse_reflexion_step(first_step_str)\n",
        "\n",
        "    return AgentFinish(\n",
        "        log=\"Reached max steps.\",\n",
        "        return_values={\"output\": answer, \"initial_answer\": initial_answer},\n",
        "    )\n",
        "\n",
        "\n",
        "def execute_tools(data):\n",
        "    agent_action = data.pop('agent_outcome')\n",
        "    observation = {t.name: t for t in tools}[agent_action.tool].invoke(agent_action.tool_input)\n",
        "    data['intermediate_steps'].append((agent_action, observation))\n",
        "    return data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "d6cdd1cd-e480-4dd7-99b4-9018eb243b4d",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AgentFinish(return_values={'output': \"The current weather in San Francisco can be accessed through various weather reporting services, which provide real-time temperature, humidity, wind, and chances of precipitation [1]. Historically, San Francisco experiences a mild, Mediterranean climate with average temperatures ranging from the low 50s to the mid-60s Fahrenheit. The city's unique topography creates microclimates, leading to significant weather variations across different neighborhoods. San Francisco's summers are notably cooler compared to other Californian cities, largely due to the cold California Current and persistent fog, especially in June and July. Winters are mild and the wettest months span from November to March, with an annual rainfall average of approximately 23 inches. Wind is a prominent feature, with spring being particularly windy. For historical weather extremes and average wind speeds, additional specific data can be sought from climatological records.\\n\\nReferences:\\n[1] https://www.weather25.com/north-america/usa/california/san-francisco\", 'initial_answer': \"The weather in San Francisco (SF) is characterized by a mild, Mediterranean-like climate with wet winters and dry summers. The city's unique topography and coastal location result in microclimates, where weather conditions can vary significantly from one neighborhood to another. Average temperatures typically range from the low 50s to the mid-60s Fahrenheit throughout the year. Summers in San Francisco are often cooler than in other parts of California due to the cold California Current offshore and the presence of fog, particularly in June and July. The fog usually burns off by the afternoon, leading to clearer skies and slightly warmer temperatures. Winters are mild and moist, with the majority of the city's rainfall occurring between November and March. Rainfall averages around 23 inches annually. Wind is also a notable feature of San Francisco's weather, with spring being the windiest season. Despite the general patterns, it's always advisable to dress in layers due to the potential for rapid weather changes.\"}, log='Reached max steps.')"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "workflow = Graph()\n",
        "\n",
        "# add actors\n",
        "workflow.add_node(\"initial\", initial_chain)\n",
        "workflow.add_node(\"next\", next_chain)\n",
        "workflow.add_node(\"finish\", finish)\n",
        "workflow.add_node(\"tools\", execute_tools)\n",
        "\n",
        "# Enter with initial actor, then loop through tools -> next steps until finished\n",
        "workflow.set_entry_point('initial')\n",
        "\n",
        "workflow.add_edge('initial', 'tools')\n",
        "workflow.add_conditional_edges(\n",
        "    'tools',\n",
        "    lambda x: \"exit\" if len(x['intermediate_steps']) >= 2 else \"continue\",\n",
        "    {\n",
        "        \"continue\": 'next',\n",
        "        \"exit\": 'finish'\n",
        "    }\n",
        ")\n",
        "workflow.add_edge('next', 'tools')\n",
        "workflow.set_finish_point('finish')\n",
        "\n",
        "chain = workflow.compile()\n",
        "\n",
        "chain.invoke({\"question\": \"what is the weather in sf\", \"intermediate_steps\": []})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9babf196-b1fd-492d-9197-96a674f5e81d",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58ce0d58-fb00-4dc1-a12b-8fc015474611",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
